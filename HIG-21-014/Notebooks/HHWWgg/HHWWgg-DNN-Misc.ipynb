{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "premium-amino",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import os \n",
    "from IPython.display import SVG, display \n",
    "import tensorflow as tf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ancient-davis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0222 21:35:40.328834 140677649540928 hdf5_format.py:211] Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "output_directory = '/eos/user/a/atishelm/www/HHWWgg/DNN/HHWWyyDNN_Binary-10Epochs_BalanceYields/'\n",
    "plots_dir = os.path.join(output_directory,'plots/')\n",
    "modelFilename = \"%s/model.h5\"%(output_directory)\n",
    "print(\"Loading model...\")\n",
    "model = keras.models.load_model(modelFilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "purple-machinery",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConversionError",
     "evalue": "converting <tensorflow.python.keras.engine.sequential.Sequential object at 0x7ff1ea4102e0>: ValueError: Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mto_graph\u001b[0;34m(entity, recursive, experimental_optional_features)\u001b[0m\n\u001b[1;32m    672\u001b[0m         autograph_module=tf_inspect.getmodule(to_graph))\n\u001b[0;32m--> 673\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mautograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogram_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/autograph/impl/conversion.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(entity, program_ctx)\u001b[0m\n\u001b[1;32m    112\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__code__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m     raise ValueError('Cannot apply autograph to a function that doesn\\'t '\n\u001b[0m\u001b[1;32m    114\u001b[0m                      \u001b[0;34m'expose a __code__ object. If this is a @tf.function,'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConversionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-45fd448cdf90>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# svg_img = tf.autograph.to_graph(model).create(prog='dot', format='svg')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# SVG(svg_img)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mto_graph\u001b[0;34m(entity, recursive, experimental_optional_features)\u001b[0m\n\u001b[1;32m    674\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNameError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Error converting %s'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 676\u001b[0;31m     raise ConversionError('converting {}: {}: {}'.format(\n\u001b[0m\u001b[1;32m    677\u001b[0m         entity, e.__class__.__name__, str(e)))\n\u001b[1;32m    678\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mConversionError\u001b[0m: converting <tensorflow.python.keras.engine.sequential.Sequential object at 0x7ff1ea4102e0>: ValueError: Cannot apply autograph to a function that doesn't expose a __code__ object. If this is a @tf.function, try passing f.python_function instead."
     ]
    }
   ],
   "source": [
    "tf.autograph.to_graph(model)\n",
    "# svg_img = tf.autograph.to_graph(model).create(prog='dot', format='svg')\n",
    "# SVG(svg_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affiliated-canyon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "consecutive-trauma",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "allied-topic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "legal-apple",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting shap\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/20/54381999efe3000f70a7f68af79ba857cfa3f82278ab0e02e6ba1c06b002/shap-0.38.1.tar.gz (352kB)\n",
      "\u001b[K     |████████████████████████████████| 358kB 6.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages (from shap) (1.18.2)\n",
      "Requirement already satisfied: scipy in /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages (from shap) (1.5.1)\n",
      "Requirement already satisfied: scikit-learn in /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages (from shap) (0.21.2)\n",
      "Requirement already satisfied: pandas in /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages (from shap) (0.24.2)\n",
      "Collecting tqdm>4.25.0 (from shap)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d9/13/f3f815bb73804a8af9cfbb6f084821c037109108885f46131045e8cf044e/tqdm-4.57.0-py2.py3-none-any.whl (72kB)\n",
      "\u001b[K     |████████████████████████████████| 81kB 10.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting slicer==0.0.7 (from shap)\n",
      "  Downloading https://files.pythonhosted.org/packages/78/c2/b3f55dfdb8af9812fdb9baf70cacf3b9e82e505b2bd4324d588888b81202/slicer-0.0.7-py3-none-any.whl\n",
      "Requirement already satisfied: numba in /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages (from shap) (0.51.2)\n",
      "Requirement already satisfied: cloudpickle in /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages (from shap) (1.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages (from pandas->shap) (2.8.0)\n",
      "Requirement already satisfied: pytz>=2011k in /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages (from pandas->shap) (2019.1)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages (from numba->shap) (0.34.0)\n",
      "Requirement already satisfied: setuptools in /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages (from numba->shap) (44.1.0)\n",
      "Requirement already satisfied: six>=1.5 in /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages (from python-dateutil>=2.5.0->pandas->shap) (1.12.0)\n",
      "Building wheels for collected packages: shap\n",
      "  Building wheel for shap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /tmp/atishelm/.cache/pip/wheels/a8/fb/e4/88012be41842b9be62ae18d82d1b1e880daf8539d1fef1fa00\n",
      "Successfully built shap\n",
      "Installing collected packages: tqdm, slicer, shap\n",
      "\u001b[33m  WARNING: The script tqdm is installed in '/eos/user/a/atishelm/.local/bin' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\n",
      "Successfully installed shap-0.38.1 slicer-0.0.7 tqdm-4.57.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --user shap "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "recognized-immigration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import shap\n",
    "import pandas\n",
    "import os\n",
    "import sklearn\n",
    "import subprocess\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, confusion_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "class plotter(object):\n",
    "\n",
    "    def __init__(self, Website):\n",
    "        self.separations_categories = []\n",
    "        self.output_directory = ''\n",
    "        #self.bin_edges_low_high = np.array([0.,0.0625,0.125,0.1875,0.25,0.3125,0.375,0.4375,0.5,0.5625,0.6125,0.6875,0.75,0.8125,0.875,0.9375,1.0])\n",
    "        self.nbins = np.linspace(0.0,1.0,num=50)\n",
    "        w, h = 4, 4\n",
    "        self.yscores_train_categorised = [[0 for x in range(w)] for y in range(h)]\n",
    "        self.yscores_test_categorised = [[0 for x in range(w)] for y in range(h)]\n",
    "        self.yscores_train_non_categorised = [[0 for x in range(w)] for y in range(h)]\n",
    "        self.yscores_test_non_categorised = [[0 for x in range(w)] for y in range(h)]\n",
    "        self.plots_directory = ''\n",
    "        self.Website = Website \n",
    "        pass\n",
    "\n",
    "    def save_plots(self, dir='plots/', filename=''):\n",
    "        self.check_dir(dir)\n",
    "        filepath = os.path.join(dir,filename)\n",
    "        self.fig.savefig(filepath)\n",
    "        return self.fig    \n",
    "    \n",
    "    def check_dir(self, dir):\n",
    "        if not os.path.exists(dir):\n",
    "            os.makedirs(dir)\n",
    "            if(self.Website != \"\"): os.system(\"cp %s/../index.php %s\"%(dir,dir))    \n",
    "    \n",
    "    def binary_overfitting(self, estimator, Y_train, Y_test, result_probs, result_probs_test, plots_dir, train_weights, test_weights, nbins=50):\n",
    "\n",
    "        model = estimator\n",
    "        data_type = type(model)\n",
    "\n",
    "        #Arrays to store all results\n",
    "        y_scores_train_signal_sample = []\n",
    "        y_scores_train_bckg_sample = []\n",
    "        y_scores_test_signal_sample = []\n",
    "        y_scores_test_bckg_sample = []\n",
    "        for i in range(0,len(result_probs)-1):\n",
    "            train_event_weight = train_weights[i]\n",
    "            if Y_train[i] == 1:\n",
    "                y_scores_train_signal_sample.append(result_probs[i])\n",
    "            if Y_train[i] == 0:\n",
    "                y_scores_train_bckg_sample.append(result_probs[i])\n",
    "        for i in range(0,len(result_probs_test)-1):\n",
    "            test_event_weight = test_weights[i]\n",
    "            if Y_test[i] == 1:\n",
    "                y_scores_test_signal_sample.append(result_probs_test[i])\n",
    "            if Y_test[i] == 0:\n",
    "                y_scores_test_bckg_sample.append(result_probs_test[i])\n",
    "\n",
    "        # Create 2D lists (dimension 2x2) to hold max DNN discriminator values for each sample. One for train data, one for test data.\n",
    "        yscores_train_binary=[]\n",
    "        yscores_test_binary=[]\n",
    "        yscores_train_binary.append([y_scores_train_signal_sample, y_scores_train_bckg_sample])\n",
    "        yscores_test_binary.append([y_scores_test_signal_sample, y_scores_test_bckg_sample])\n",
    "\n",
    "        counter =0\n",
    "        separations_all = []\n",
    "        for y_scores_train_nonCat,y_scores_test_nonCat in zip(yscores_train_binary,yscores_test_binary):\n",
    "            colours = ['r','steelblue']\n",
    "            plot_title = 'Binary'\n",
    "            plot_info = [colours,data_type,plots_dir,plot_title]\n",
    "            separations_all.append(self.draw_binary_overfitting_plot(y_scores_train_nonCat,y_scores_test_nonCat,plot_info,test_weights))\n",
    "            counter = counter+1\n",
    "\n",
    "        return\n",
    "    def plot_dot(self, title, x, shap_values, column_headers):\n",
    "        plt.figure()\n",
    "        if x is None:\n",
    "          print('<plotter> No x defined. Leaving class function')\n",
    "          return\n",
    "        shap.summary_plot(shap_values[0], features=x, feature_names=column_headers, show=False, max_display=10)\n",
    "        plt.gca().set_title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"{}/plots/{}.png\".format(self.output_directory, title), bbox_inches='tight')\n",
    "        plt.savefig(\"{}/plots/{}.pdf\".format(self.output_directory, title), bbox_inches='tight')\n",
    "\n",
    "    def plot_dot_bar(self, title, x, shap_values, column_headers):\n",
    "        plt.figure()\n",
    "        if x is None:\n",
    "            print('<plotter> No x defined. Leaving class function')\n",
    "            return\n",
    "        shap.summary_plot(shap_values[0], features=x, feature_names=column_headers, show=False,plot_type='bar',max_display=10)\n",
    "        plt.gca().set_title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"{}/plots/{}.png\".format(self.output_directory,title), bbox_inches='tight')\n",
    "        plt.savefig(\"{}/plots/{}.pdf\".format(self.output_directory,title), bbox_inches='tight')\n",
    "\n",
    "    def plot_dot_bar_all(self , title, x, shap_values, column_headers):\n",
    "        plt.figure()\n",
    "        if x is None:\n",
    "            print('<plotter> No x defined. Leaving class function')\n",
    "            return\n",
    "        shap.summary_plot(shap_values[0], features=x, feature_names=column_headers, show=False,plot_type='bar',max_display=len(column_headers))\n",
    "        plt.gca().set_title(title)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"{}/plots/{}.png\".format(self.output_directory,title), bbox_inches='tight')\n",
    "        plt.savefig(\"{}/plots/{}.pdf\".format(self.output_directory,title), bbox_inches='tight')\n",
    "\n",
    "    def GetSeparation(self, hist_sig, hist_bckg):\n",
    "\n",
    "\n",
    "        minima = np.minimum(hist_sig, hist_bckg)\n",
    "        intersection = np.true_divide(np.sum(minima), np.sum(hist_bckg))\n",
    "        return intersection\n",
    "\n",
    "        '''\n",
    "        # compute \"separation\" defined as\n",
    "        # <s2> = (1/2) Int_-oo..+oo { (S(x) - B(x))^2/(S(x) + B(x)) dx }\n",
    "        separation = 0;\n",
    "        # sanity check: signal and background histograms must have same number of bins and same limits\n",
    "        if len(hist_sig) != len(hist_bckg):\n",
    "            print 'Number of bins different for sig. and bckg'\n",
    "\n",
    "        nBins = len(hist_sig)\n",
    "        nS = np.sum(hist_sig)\n",
    "        nB = np.sum(hist_bckg)\n",
    "\n",
    "        if nS == 0:\n",
    "            print 'WARNING: no signal'\n",
    "        if nB == 0:\n",
    "            print 'WARNING: no bckg'\n",
    "\n",
    "        for i in range(1,nBins):\n",
    "            # No need to norm as already done?\n",
    "            sig_bin_norm = hist_sig[i]/nS\n",
    "            #sig_bin_norm = hist_sig[i]\n",
    "            bckg_bin_norm = hist_bckg[i]/nB\n",
    "            #bckg_bin_norm = hist_bckg[i]\n",
    "            # Separation:\n",
    "            if(sig_bin_norm+bckg_bin_norm > 0):\n",
    "                separation += 0.5 * ((sig_bin_norm - bckg_bin_norm) * (sig_bin_norm - bckg_bin_norm)) / (sig_bin_norm + bckg_bin_norm)\n",
    "        #separation *= dX\n",
    "        return separation'''         \n",
    "        \n",
    "    def draw_binary_overfitting_plot(self, y_scores_train, y_scores_test, plot_info, test_weights):\n",
    "        colours = plot_info[0]\n",
    "        data_type = plot_info[1]\n",
    "        plots_dir = plot_info[2]\n",
    "        plot_title = plot_info[3]\n",
    "        name = filter(str.isalnum, str(data_type).split(\".\")[-1])\n",
    "        self.fig, self.ax = plt.subplots(figsize=(8,6))\n",
    "        self.ax.grid(which='major', linestyle='-', linewidth='0.2', color='gray')\n",
    "        self.ax.set_facecolor('white')\n",
    "\n",
    "        bin_edges_low_high = np.array([0.,0.0625,0.125,0.1875,0.25,0.3125,0.375,0.4375,0.5,0.5625,0.6125,0.675,0.7375,0.8,0.8625,0.9375,1.0])\n",
    "\n",
    "        index=0\n",
    "        for index in range(0,len(y_scores_train)):\n",
    "            train_bin_errors = np.zeros(len(bin_edges_low_high)-1)\n",
    "            test_bin_errors = np.zeros(len(bin_edges_low_high)-1)\n",
    "\n",
    "            y_train = y_scores_train[index]\n",
    "            y_test = y_scores_test[index]\n",
    "            colour = colours[index]\n",
    "            width = np.diff(bin_edges_low_high)\n",
    "            if index==0:\n",
    "                print('<plotter> Overfitting plot: Signal')\n",
    "                label='signal'\n",
    "            if index==1:\n",
    "                label='bckg'\n",
    "                print('<plotter> Overfitting plot: Background')\n",
    "\n",
    "            # Setup training histograms\n",
    "            histo_train_, bin_edges = np.histogram(y_train, bins=bin_edges_low_high)\n",
    "            dx_scale_train =(bin_edges[len(bin_edges)-1] - bin_edges[0]) / (len(bin_edges)-1)\n",
    "            bincenters = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "\n",
    "            bin_errors_sumw2 = 0\n",
    "\n",
    "            # Scale training histograms to: (hist / sum of histogram entries) / (range / number of bins)\n",
    "            # so like scaling hist relative to its integral.\n",
    "            # then scaling the result relative to its avergae bin width.\n",
    "            histo_train_ = (histo_train_ / np.sum(histo_train_, dtype=np.float32)) / dx_scale_train\n",
    "            plt.bar(bincenters, histo_train_, width=width, color=colour, edgecolor=colour, alpha=0.5, label=label+' training')\n",
    "\n",
    "            if index == 0:\n",
    "                histo_train_sig = histo_train_\n",
    "            if index == 1:\n",
    "                histo_train_bckg = histo_train_\n",
    "\n",
    "            histo_test_, bin_edges = np.histogram(y_test, bins=bin_edges_low_high)\n",
    "            dx_scale_test =(bin_edges[len(bin_edges)-1] - bin_edges[0]) / (len(bin_edges)-1)\n",
    "            bincenters = 0.5*(bin_edges[1:]+bin_edges[:-1])\n",
    "\n",
    "            # Protection against low stats in validation dataset.\n",
    "            if np.sum(histo_test_, dtype=np.float32) <= 0 :\n",
    "                histo_test_ = histo_test_\n",
    "                err = 0\n",
    "                plt.errorbar(bincenters, histo_test_, yerr=err, fmt='o', c=colour, label=label+' testing')\n",
    "                if index == 0:\n",
    "                    histo_test_sig = histo_test_\n",
    "                if index == 1:\n",
    "                    histo_test_bckg = histo_test_\n",
    "            else:\n",
    "                # Currently just taking the sqrt of the bin entry\n",
    "                # Correct way:\n",
    "                # Errors calculated using error propogation and the histograms intrinsic poissonian statistics\n",
    "                # err(sum weights)^2 == variance on the sum of weights = sum of the variance of each weight =  sum{var(w_i)} [i=1,2,N]\n",
    "                # Varianceof weight i is determined by the statistical fluctuation of the number of events considered.\n",
    "                # var(w_i) = var(w_i * 1 event) = w_i^2 * var(1 event) = w_i^2\n",
    "                # err(sum weights) = sqrt( sum{var(w_i)}[i=1,2,N] )\n",
    "                #                  = sqrt( sum{w_i^2}[i=1,2,N] )\n",
    "                bin_errors_sumw2 = 0\n",
    "                for yval_index in range(0,len(y_scores_test[0])):\n",
    "                    for bin_index in range(0,len(bin_edges_low_high)-1):\n",
    "                        bin_low_edge = bin_edges_low_high[bin_index]\n",
    "                        bin_high_edge = bin_edges_low_high[bin_index+1]\n",
    "                        if y_scores_test[0][yval_index] > bin_low_edge and y_scores_test[0][yval_index] < bin_high_edge:\n",
    "                            test_bin_errors[[bin_index]] += 1#test_weights[yval_index]**2\n",
    "                # Take square root of sum of bins.\n",
    "                test_bin_errors = (np.sqrt(test_bin_errors)/np.sum(histo_test_, dtype=np.float32)) / dx_scale_test\n",
    "                #test_bin_errors = np.sqrt(( test_bin_errors/np.sum(histo_test_, dtype=np.float32) ) / dx_scale_test )\n",
    "                histo_test_ = ( histo_test_ / np.sum(histo_test_, dtype=np.float32) ) / dx_scale_test\n",
    "                #err = np.sqrt(histo_test_/np.sum(histo_test_, dtype=np.float32))\n",
    "                #err = np.sqrt(histo_test_)\n",
    "\n",
    "                plt.errorbar(bincenters, histo_test_, yerr=test_bin_errors, fmt='o', c=colour, label=label+' testing')\n",
    "                if index == 0:\n",
    "                    histo_test_sig = histo_test_\n",
    "                if index == 1:\n",
    "                    histo_test_bckg = histo_test_\n",
    "\n",
    "\n",
    "        train_SvsBSep = \"{0:.5g}\".format(self.GetSeparation(histo_train_sig,histo_train_bckg))\n",
    "        test_SvsBSep = \"{0:.5g}\".format(self.GetSeparation(histo_test_sig,histo_test_bckg))\n",
    "\n",
    "        S_v_B_train_sep = 'SvsB train Sep.: %s' % ( train_SvsBSep )\n",
    "        self.ax.annotate(S_v_B_train_sep,  xy=(0.7, 2.5), xytext=(0.7, 2.5), fontsize=9)\n",
    "        S_v_B_test_sep = 'SvsB test Sep.: %s' % ( test_SvsBSep )\n",
    "        self.ax.annotate(S_v_B_test_sep,  xy=(0.7, 1.75), xytext=(0.7, 1.5), fontsize=9)\n",
    "\n",
    "        separations_forTable = r'''%s & \\textbackslash ''' % (S_v_B_test_sep)\n",
    "\n",
    "        title_ = '%s output node' % (plot_title)\n",
    "        plt.title(title_)\n",
    "        label_name = 'Output Score'\n",
    "        plt.xlabel(label_name)\n",
    "        plt.ylabel('(1/N)dN/dX')\n",
    "\n",
    "        leg = plt.legend(loc='best', frameon=False, fancybox=False, fontsize=9)\n",
    "        leg.get_frame().set_edgecolor('w')\n",
    "        frame = leg.get_frame()\n",
    "        frame.set_facecolor('White')\n",
    "\n",
    "        overfitting_plot_file_name = 'overfitting_plot_BinaryClassifier_%s.pdf' % (plot_title)\n",
    "        print('Saving : %s%s' % (plots_dir, overfitting_plot_file_name))\n",
    "        self.save_plots(dir=plots_dir, filename=overfitting_plot_file_name)\n",
    "        \n",
    "#         overfitting_plot_file_name = 'overfitting_plot_BinaryClassifier_%s.pdf' % (plot_title)\n",
    "#         print('Saving : %s%s' % (plots_dir, overfitting_plot_file_name))\n",
    "#         self.save_plots(dir=plots_dir, filename=overfitting_plot_file_name)        \n",
    "        return separations_forTable     \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ready-twins",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# from tensorflow import keras \n",
    "import argparse\n",
    "import pickle \n",
    "import os \n",
    "import pandas as pd \n",
    "import h5py \n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "occupational-finland",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "optional-sender",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0222 08:54:19.803083 140074485446464 hdf5_format.py:211] Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading X_train...\n",
      "X_train = pickle.load( open( '/eos/user/a/atishelm/www/HHWWgg/DNN/HHWWyyDNN_Binary-10Epochs_BalanceYields//X_train.p', 'rb' ), encoding='latin1' )\n",
      "Loading X_test...\n",
      "X_test = pickle.load( open( '/eos/user/a/atishelm/www/HHWWgg/DNN/HHWWyyDNN_Binary-10Epochs_BalanceYields//X_test.p', 'rb' ), encoding='latin1' )\n",
      "Loading Y_test...\n",
      "Y_test = pickle.load( open( '/eos/user/a/atishelm/www/HHWWgg/DNN/HHWWyyDNN_Binary-10Epochs_BalanceYields//Y_test.p', 'rb' ), encoding='latin1' )\n",
      "Loading Y_train...\n",
      "Y_train = pickle.load( open( '/eos/user/a/atishelm/www/HHWWgg/DNN/HHWWyyDNN_Binary-10Epochs_BalanceYields//Y_train.p', 'rb' ), encoding='latin1' )\n",
      "Loading train_weights...\n",
      "train_weights = pickle.load( open( '/eos/user/a/atishelm/www/HHWWgg/DNN/HHWWyyDNN_Binary-10Epochs_BalanceYields//train_weights.p', 'rb' ), encoding='latin1' )\n",
      "Loading test_weights...\n",
      "test_weights = pickle.load( open( '/eos/user/a/atishelm/www/HHWWgg/DNN/HHWWyyDNN_Binary-10Epochs_BalanceYields//test_weights.p', 'rb' ), encoding='latin1' )\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cd8372f2c533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecuteLine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mresult_probs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mresult_probs_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# train_weights = abs(traindataset['weight'].values)*abs(traindataset['weight_NLO_SM'].values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# output_directory = '/eos/user/a/atishelm/www/DNN/HHWWyyDNN_200Epochs-MultiClass-2Classes_BalanceYields/'\n",
    "output_directory = '/eos/user/a/atishelm/www/HHWWgg/DNN/HHWWyyDNN_Binary-10Epochs_BalanceYields/'\n",
    "plots_dir = os.path.join(output_directory,'plots/')\n",
    "modelFilename = \"%s/model.h5\"%(output_directory)\n",
    "print(\"Loading model...\")\n",
    "model = keras.models.load_model(modelFilename)\n",
    "\n",
    "objectsToLoad = [\"X_train\", \"X_test\", \"Y_test\",\"Y_train\",\"train_weights\",\"test_weights\"]\n",
    "for objToLoad in objectsToLoad:\n",
    "    print(\"Loading %s...\"%(objToLoad))\n",
    "    executeLine = \"%s = pickle.load( open( '%s/%s.p', 'rb' ), encoding='latin1' )\"%(objToLoad, output_directory, objToLoad) ##-- encoding='latin1' to avoid python 2 / 3 numpy array incompatibility: https://stackoverflow.com/questions/11305790/pickle-incompatibility-of-numpy-arrays-between-python-2-and-3\n",
    "    print(executeLine)\n",
    "    exec(executeLine)\n",
    "\n",
    "result_probs = model.predict(np.array(X_train))\n",
    "result_probs_test = model.predict(np.array(X_test))\n",
    "# train_weights = abs(traindataset['weight'].values)*abs(traindataset['weight_NLO_SM'].values)\n",
    "# test_weights = abs(valdataset['weight'].values)*abs(valdataset['weight_NLO_SM'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "plastic-smell",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0222 08:54:27.416645 140074485446464 hdf5_format.py:211] Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "output_directory = '/eos/user/a/atishelm/www/HHWWgg/DNN/HHWWyyDNN_Binary-10Epochs_BalanceYields/'\n",
    "plots_dir = os.path.join(output_directory,'plots/')\n",
    "modelFilename = \"%s/model.h5\"%(output_directory)\n",
    "print(\"Loading model...\")\n",
    "model = keras.models.load_model(modelFilename)\n",
    "\n",
    "model_schematic_name = os.path.join(output_directory,'model_schematic.pdf')\n",
    "plot_model(model, to_file=model_schematic_name, show_shapes=True, show_layer_names=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "national-gentleman",
   "metadata": {},
   "outputs": [],
   "source": [
    "Website = '/eos/user/a/atishelm/www/HHWWgg/DNN/'\n",
    "Plotter = plotter(Website)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "waiting-mining",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "StagingError",
     "evalue": "in user code:\n\n    /eos/user/a/atishelm/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:248 grad_graph  *\n        x_grad = tape.gradient(out, shap_rAnD)\n    /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:1067 gradient  **\n        flat_grad = imperative_grad.imperative_grad(\n    /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py:71 imperative_grad\n        return pywrap_tfe.TFE_Py_TapeGradient(\n    /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:151 _gradient_function\n        grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access\n    /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/framework/registry.py:96 lookup\n        raise LookupError(\n\n    LookupError: gradient registry has no entry for: shap_AddV2\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStagingError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-7419d69c2ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Plotter.binary_overfitting(model, Y_train, Y_test, result_probs, result_probs_test, plots_dir, train_weights, test_weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDeepExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mshap_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;31m# Plotter.plot_dot(title=\"DeepExplainer_sigmoid_y0\", x=X_test[:400, ], shap_values=shap_values, column_headers=column_headers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Plotter.plot_dot_bar(title=\"DeepExplainer_Bar_sigmoid_y0\", x=X_test[:400,], shap_values=shap_values, column_headers=column_headers)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/__init__.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mwere\u001b[0m \u001b[0mchosen\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0;34m\"top\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \"\"\"\n\u001b[0;32m--> 124\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mranked_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_rank_order\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_additivity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_additivity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py\u001b[0m in \u001b[0;36mshap_values\u001b[0;34m(self, X, ranked_outputs, output_rank_order, check_additivity)\u001b[0m\n\u001b[1;32m    306\u001b[0m                 \u001b[0;31m# run attribution computation graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m                 \u001b[0mfeature_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_output_ranks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m                 \u001b[0msample_phis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphi_symbolic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjoint_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 \u001b[0;31m# assign the attributions to the right part of the output arrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, out, model_inputs, X)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfinal_out\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute_with_overridden_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcustom_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py\u001b[0m in \u001b[0;36mexecute_with_overridden_gradients\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;31m# define the computation graph for the attribution values using a custom gradient-like computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    400\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 401\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    402\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0;31m# reinstate the backpropagatable check\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py\u001b[0m in \u001b[0;36manon\u001b[0;34m()\u001b[0m\n\u001b[1;32m    359\u001b[0m                     \u001b[0mv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    360\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 361\u001b[0;31m                 \u001b[0mfinal_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    362\u001b[0m                 \u001b[0mtf_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_gradient\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_backprop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_record_gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    821\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    822\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 823\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    824\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    825\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_deleter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFunctionDeleter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lifted_initializer_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    695\u001b[0m     self._concrete_stateful_fn = (\n\u001b[0;32m--> 696\u001b[0;31m         self._stateful_fn._get_concrete_function_internal_garbage_collected(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    697\u001b[0m             *args, **kwds))\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_internal_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2853\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2854\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2855\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2856\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3212\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3213\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3214\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3215\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3063\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3064\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3065\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3066\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3067\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    984\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 986\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    988\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;31m# __wrapped__ allows AutoGraph to swap in a converted function. We give\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m     \u001b[0mweak_wrapped_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapped_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mStagingError\u001b[0m: in user code:\n\n    /eos/user/a/atishelm/.local/lib/python3.8/site-packages/shap/explainers/_deep/deep_tf.py:248 grad_graph  *\n        x_grad = tape.gradient(out, shap_rAnD)\n    /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:1067 gradient  **\n        flat_grad = imperative_grad.imperative_grad(\n    /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/imperative_grad.py:71 imperative_grad\n        return pywrap_tfe.TFE_Py_TapeGradient(\n    /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/eager/backprop.py:151 _gradient_function\n        grad_fn = ops._gradient_registry.lookup(op_name)  # pylint: disable=protected-access\n    /cvmfs/sft.cern.ch/lcg/views/LCG_99/x86_64-centos7-gcc8-opt/lib/python3.8/site-packages/tensorflow/python/framework/registry.py:96 lookup\n        raise LookupError(\n\n    LookupError: gradient registry has no entry for: shap_AddV2\n"
     ]
    }
   ],
   "source": [
    "# Make overfitting plots of output nodes\n",
    "\n",
    "\n",
    "\n",
    "# Plotter.binary_overfitting(model, Y_train, Y_test, result_probs, result_probs_test, plots_dir, train_weights, test_weights)\n",
    "e = shap.DeepExplainer(model, X_train[:400, ])\n",
    "shap_values = e.shap_values(X_test[:400, ])\n",
    "# Plotter.plot_dot(title=\"DeepExplainer_sigmoid_y0\", x=X_test[:400, ], shap_values=shap_values, column_headers=column_headers)\n",
    "# Plotter.plot_dot_bar(title=\"DeepExplainer_Bar_sigmoid_y0\", x=X_test[:400,], shap_values=shap_values, column_headers=column_headers)\n",
    "\n",
    "# e = shap.GradientExplainer(model, X_train[:100, ])\n",
    "# shap_values = e.shap_values(X_test[:100, ])\n",
    "# Plotter.plot_dot(title=\"GradientExplainer_sigmoid_y0\", x=X_test[:100, ], shap_values=shap_values, column_headers=column_headers)\n",
    "# e = shap.KernelExplainer(model.predict, X_train[:100, ])\n",
    "# shap_values = e.shap_values(X_test[:100, ])\n",
    "# Plotter.plot_dot(title=\"KernelExplainer_sigmoid_y0\", x=X_test[:100, ],shap_values=shap_values, column_headers=column_headers)\n",
    "# Plotter.plot_dot_bar(title=\"KernelExplainer_Bar_sigmoid_y0\", x=X_test[:100,], shap_values=shap_values, column_headers=column_headers)\n",
    "# Plotter.plot_dot_bar_all(title=\"KernelExplainer_bar_All_Var_sigmoid_y0\", x=X_test[:100,], shap_values=shap_values, column_headers=column_headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governing-worthy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
